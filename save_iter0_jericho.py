"""
ç®€å•è„šæœ¬ï¼šåŠ è½½ Qwen2.5-7B æ¨¡å‹å¹¶ä¿å­˜ä¸º iter0
ç”¨äº orz_7b_ppo_jericho_1013_1gpu å®éªŒ

è¿è¡Œå‘½ä»¤:
python save_iter0_jericho.py
"""
import os
from transformers import AutoModelForCausalLM, AutoTokenizer

# é…ç½®å‚æ•°
MODEL_PATH = "/mnt/shared-storage-user/tangjia/orz/Open-Reasoner-Zero/model/models--Qwen--Qwen2.5-7B/snapshots/e25af2efae60472008fbeaf5fb7c4274a87f78d4"
SAVE_BASE_PATH = "jericho_his10_orz_20251013_ckpt_1gpu/orz_7b_ppo_jericho_1013_1gpu"

def main():
    print("="*80)
    print("å¼€å§‹ä¿å­˜ iter0 æ¨¡å‹")
    print("="*80)

    # 1. åŠ è½½æ¨¡å‹
    print(f"\n[1/4] åŠ è½½æ¨¡å‹: {MODEL_PATH}")
    model = AutoModelForCausalLM.from_pretrained(
        MODEL_PATH,
        trust_remote_code=True,
        torch_dtype="auto",
        device_map="auto"
    )
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")

    # 2. åŠ è½½ tokenizer
    print(f"\n[2/4] åŠ è½½ tokenizer: {MODEL_PATH}")
    tokenizer = AutoTokenizer.from_pretrained(
        MODEL_PATH,
        trust_remote_code=True
    )
    print("âœ… Tokenizer åŠ è½½å®Œæˆ")

    # 3. ä¿å­˜ policy æ¨¡å‹
    policy_save_path = os.path.join(SAVE_BASE_PATH, "iter0", "policy")
    print(f"\n[3/4] ä¿å­˜ policy æ¨¡å‹åˆ°: {policy_save_path}")
    os.makedirs(policy_save_path, exist_ok=True)
    model.save_pretrained(policy_save_path)
    tokenizer.save_pretrained(policy_save_path)
    print("âœ… Policy æ¨¡å‹ä¿å­˜å®Œæˆ")

    # 4. ä¿å­˜ critic æ¨¡å‹ï¼ˆä¸ policy ç›¸åŒï¼‰
    critic_save_path = os.path.join(SAVE_BASE_PATH, "iter0", "critic")
    print(f"\n[4/4] ä¿å­˜ critic æ¨¡å‹åˆ°: {critic_save_path}")
    os.makedirs(critic_save_path, exist_ok=True)
    model.save_pretrained(critic_save_path)
    tokenizer.save_pretrained(critic_save_path)
    print("âœ… Critic æ¨¡å‹ä¿å­˜å®Œæˆ")

    print("\n" + "="*80)
    print("ğŸ‰ æ‰€æœ‰æ¨¡å‹å·²æˆåŠŸä¿å­˜åˆ° iter0ï¼")
    print("="*80)
    print(f"\nPolicy æ¨¡å‹ä½ç½®: {policy_save_path}")
    print(f"Critic æ¨¡å‹ä½ç½®: {critic_save_path}")
    print("\nå¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼")

if __name__ == "__main__":
    main()
